{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "053fe87f-5a42-4764-8669-379ef6673cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.transformation.general import GiveUniqueNodeNames, GiveReadableTensorNames, RemoveStaticGraphInputs\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from finn.util.visualization import showInNetron\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "\n",
    "# 1. å®šä¹‰æ–‡ä»¶å\n",
    "onnx_file = \"lenet_w2a1_mixed.onnx\"\n",
    "\n",
    "build_dir = \"output_lenet\" # å®šä¹‰è¾“å‡ºç›®å½•\n",
    "if not os.path.exists(build_dir):\n",
    "    os.makedirs(build_dir)\n",
    "\n",
    "# 1. åŠ è½½æ¨¡å‹\n",
    "model = ModelWrapper(onnx_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a98d1baa-c34f-4b15-97e4-ad83ea2bc699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serving 'lenet_w2a1_mixed.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7d718dc27790>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(onnx_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0878ae6-7aa5-4620-b134-c72f8c96f859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨è½¬æ¢ä¸º FINN æ ¼å¼...\n",
      "æ­£åœ¨æ‰§è¡Œæ¸…ç†...\n",
      "âœ… ç¬¬ä¸€æ­¥å®Œæˆï¼šæ¨¡å‹å·²è½¬æ¢ä¸º FINN æ ¼å¼å¹¶æ¸…ç†å®Œæ¯•ã€‚\n"
     ]
    }
   ],
   "source": [
    "# 2. è½¬æ¢ä¸º FINN æ ¼å¼ (MultiThreshold)\n",
    "print(\"æ­£åœ¨è½¬æ¢ä¸º FINN æ ¼å¼...\")\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "\n",
    "# 3. åŸºç¡€æ¸…ç†ä¸å¸¸é‡æŠ˜å  (Tidy-up)\n",
    "# åå¤è¿è¡Œä»¥ç¡®ä¿æ‰€æœ‰æƒé‡è¢«å†»ç»“ä¸º Initializer\n",
    "print(\"æ­£åœ¨æ‰§è¡Œæ¸…ç†...\")\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "\n",
    "# ä¿å­˜å¹¶æŸ¥çœ‹\n",
    "model.save(build_dir + \"/step1_tidy.onnx\")\n",
    "print(\"âœ… ç¬¬ä¸€æ­¥å®Œæˆï¼šæ¨¡å‹å·²è½¬æ¢ä¸º FINN æ ¼å¼å¹¶æ¸…ç†å®Œæ¯•ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37191439-f71a-4803-bb3e-866763d2ad59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serving 'output_lenet/step1_tidy.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f360b3dfa90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir + \"/step1_tidy.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15586543-6a2a-4d85-ab84-0661772e7152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ç¬¬äºŒæ­¥å®Œæˆï¼šå·²æ·»åŠ é¢„å¤„ç†å’Œ TopKã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxwellqin/projects/finn/deps/qonnx/src/qonnx/transformation/merge_onnx_models.py:70: UserWarning: [MergeONNXModels] opsets for models to merge differ: 14 vs 11, output model will use opset 14\n",
      "  warnings.warn(\n",
      "/home/maxwellqin/projects/finn/deps/qonnx/src/qonnx/transformation/infer_data_layouts.py:127: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    }
   ],
   "source": [
    "from finn.util.pytorch import ToTensor\n",
    "from finn.util.pytorch import Normalize\n",
    "from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "from qonnx.core.datatype import DataType\n",
    "from qonnx.transformation.insert_topk import InsertTopK\n",
    "\n",
    "# 1. åˆ›å»ºé¢„å¤„ç†æ¨¡å‹ (é™¤ä»¥ 255)\n",
    "global_inp_name = model.graph.input[0].name\n",
    "ishape = model.get_tensor_shape(global_inp_name)\n",
    "totensor_pyt = Normalize(torch.tensor(33.3285,), torch.tensor(78.5655,),1) \n",
    "export_path = build_dir + \"/preproc.onnx\"\n",
    "# ä¸´æ—¶å¯¼å‡ºä¸€ä¸ªå°æ¨¡å‹\n",
    "from brevitas.export import export_qonnx\n",
    "export_qonnx(totensor_pyt, torch.randn(ishape), export_path)\n",
    "\n",
    "# 2. åˆå¹¶é¢„å¤„ç†\n",
    "pre_model = ModelWrapper(export_path)\n",
    "model = model.transform(MergeONNXModels(pre_model))\n",
    "\n",
    "# 3. æ˜¾å¼æ ‡è®°è¾“å…¥ä¸º UINT8 (è¿™å¯¹ FPGA å¾ˆé‡è¦)\n",
    "global_inp_name = model.graph.input[0].name\n",
    "model.set_tensor_datatype(global_inp_name, DataType[\"UINT8\"])\n",
    "\n",
    "# 4. æ·»åŠ åå¤„ç† (Top-1)\n",
    "model = model.transform(InsertTopK(k=1))\n",
    "\n",
    "# 5. å†æ¬¡æ¸…ç†\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "\n",
    "model.save(build_dir + \"/step2_pre_post.onnx\")\n",
    "print(\"âœ… ç¬¬äºŒæ­¥å®Œæˆï¼šå·²æ·»åŠ é¢„å¤„ç†å’Œ TopKã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2df82607-830b-496f-9ea8-427b317069cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serving 'output_lenet/step2_pre_post.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7d93e77354b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir + \"/step2_pre_post.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a2c4cf5-3e01-451f-986e-d34712af7a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ç¬¬ä¸‰æ­¥å®Œæˆï¼šæ¨¡å‹å·²æµçº¿åŒ–å¹¶è½¬æ¢ä¸º MatMulã€‚\n"
     ]
    }
   ],
   "source": [
    "from finn.transformation.streamline import Streamline\n",
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from qonnx.transformation.bipolar_to_xnor import ConvertBipolarMatMulToXnorPopcount\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC, MoveScalarLinearPastInvariants\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.general import RemoveUnusedTensors\n",
    "\n",
    "model = ModelWrapper(build_dir + \"/step2_pre_post.onnx\")\n",
    "model = model.transform(MoveScalarLinearPastInvariants())\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(MakeMaxPoolNHWC())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(Streamline())\n",
    "# absorb final add-mul nodes into TopK\n",
    "model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "model.save(build_dir + \"/lenet_streamlined.onnx\")\n",
    "\n",
    "# ä¿å­˜ç»“æœ\n",
    "model.save(build_dir + \"/lenet_streamlined.onnx\")\n",
    "print(\"âœ… ç¬¬ä¸‰æ­¥å®Œæˆï¼šæ¨¡å‹å·²æµçº¿åŒ–å¹¶è½¬æ¢ä¸º MatMulã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71d6e69f-2f7e-4668-9cbb-ab5dc49bc785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serving 'output_lenet/lenet_streamlined.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7d70c8b5d870>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir + \"/lenet_streamlined.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44a91369-56f3-4ba1-87ab-21c8a71f8a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing CNV to FC Flatten/Reshape...\n",
      "Creating Dataflow Partition...\n",
      "Specializing layers for Pynq-Z1 (xc7z020clg400-1)...\n",
      "âœ… HW conversion complete. Saved to output_lenet/lenet_dataflow_model.onnx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (\n",
    "    CreateDataflowPartition,\n",
    ")\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "from finn.transformation.fpgadataflow.specialize_layers import SpecializeLayers\n",
    "from finn.transformation.streamline.absorb import AbsorbConsecutiveTransposes\n",
    "from qonnx.custom_op.registry import getCustomOp\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.general import RemoveUnusedTensors, GiveUniqueNodeNames\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from finn.util.basic import pynq_part_map\n",
    "# æ¿å¡è®¾ç½®\n",
    "pynq_board = \"Pynq-Z1\" \n",
    "fpga_part = pynq_part_map[pynq_board]\n",
    "target_clk_ns = 10\n",
    "# ===========================================\n",
    "\n",
    "model = ModelWrapper(build_dir + \"/lenet_streamlined.onnx\")\n",
    "\n",
    "# 1. å°†é€šç”¨å±‚è½¬æ¢ä¸º HW ç¡¬ä»¶å±‚\n",
    "# å¤„ç†çº¯äºŒå€¼åŒ–å±‚ (W1A1)\n",
    "model = model.transform(to_hw.InferBinaryMatrixVectorActivation())\n",
    "# å¤„ç†å¤šæ¯”ç‰¹/æ··åˆç²¾åº¦å±‚ (å…³é”®: å¤„ç†ä½ çš„ INT2 æƒé‡)\n",
    "model = model.transform(to_hw.InferQuantizedMatrixVectorActivation())\n",
    "\n",
    "# 2. å¤„ç†ç‰¹å®šåŠŸèƒ½å±‚\n",
    "model = model.transform(to_hw.InferLabelSelectLayer())    # TopK -> LabelSelect\n",
    "model = model.transform(to_hw.InferThresholdingLayer())   # é˜ˆå€¼å±‚ -> Thresholding_Batch\n",
    "model = model.transform(to_hw.InferConvInpGen())          # Im2Col -> SlidingWindow\n",
    "model = model.transform(to_hw.InferStreamingMaxPool())    # MaxPool -> StreamingMaxPool\n",
    "\n",
    "# 3. æ¸…ç†è¿æ¥å±‚ (è§£å†³ä¹‹å‰çš„ Flatten/Reshape é—®é¢˜)\n",
    "# è¿™ä¸€æ­¥ä¼šè¯†åˆ« Transpose->Reshape æ¨¡å¼ï¼Œå°†å…¶ç§»é™¤å¹¶é‡æ’åç»­ MatMul çš„æƒé‡\n",
    "print(\"Removing CNV to FC Flatten/Reshape...\")\n",
    "model = model.transform(RemoveCNVtoFCFlatten())\n",
    "\n",
    "# åˆå¹¶è¿ç»­çš„ Transpose\n",
    "model = model.transform(AbsorbConsecutiveTransposes())\n",
    "\n",
    "# 4. æ•´ç†å›¾ç»“æ„ä¸æ•°æ®å¸ƒå±€\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "\n",
    "# 5. æ•°æ®æµåˆ†åŒº (Dataflow Partitioning)\n",
    "print(\"Creating Dataflow Partition...\")\n",
    "parent_model = model.transform(CreateDataflowPartition())\n",
    "parent_model.save(build_dir + \"/lenet_dataflow_parent.onnx\")\n",
    "\n",
    "# 6. æå–å­å›¾å¹¶ä¸“é—¨åŒ–ä¸º HLS å˜ä½“ (Specialize Layers)\n",
    "# è·å–åˆ†åŒºåçš„å­å›¾æ¨¡å‹æ–‡ä»¶å\n",
    "sdp_node = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")[0]\n",
    "sdp_node = getCustomOp(sdp_node)\n",
    "dataflow_model_filename = sdp_node.get_nodeattr(\"model\")\n",
    "\n",
    "# åŠ è½½å­å›¾å¹¶è½¬æ¢ä¸º HLS å±‚\n",
    "print(f\"Specializing layers for {pynq_board} ({fpga_part})...\")\n",
    "dataflow_model = ModelWrapper(dataflow_model_filename)\n",
    "dataflow_model = dataflow_model.transform(SpecializeLayers(fpga_part))\n",
    "\n",
    "# ä¿å­˜æœ€ç»ˆç»“æœ\n",
    "save_path = build_dir + \"/lenet_dataflow_model.onnx\" \n",
    "dataflow_model.save(save_path)\n",
    "\n",
    "print(f\"âœ… HW conversion complete. Saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "398033d0-1a95-41bb-91ae-0801d6d6be2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serving 'output_lenet/lenet_dataflow_model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7d854c2f7fd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir + \"/lenet_dataflow_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b34cce6-d828-4925-bc8c-9d7c89057fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serving 'output_lenet/lenet_dataflow_parent.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7d854c23b3a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æŸ¥çœ‹çˆ¶æ¨¡å‹ï¼ˆå¤–å£³ï¼‰\n",
    "showInNetron(build_dir + \"/lenet_dataflow_parent.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d81159a-bec6-44ec-a437-4c9b7c3287fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å¼€å§‹ Step 5: é…ç½®å¹¶è¡Œåº¦ (Folding)...\n",
      "Layer : SIMD=1 (Safe Mode)\n",
      "Layer : SIMD=1 (Safe Mode)\n",
      "Layer : SIMD=1 (Safe Mode)\n",
      "âœ… Step 5 å®Œæˆï¼æ¨¡å‹å·²ä¿å­˜è‡³: output_lenet/lenet_folded.onnx\n"
     ]
    }
   ],
   "source": [
    "# ã€å…³é”®ä¿®æ­£ã€‘ä» qonnx å¯¼å…¥ ModelWrapperï¼Œè€Œä¸æ˜¯ finn.core\n",
    "from qonnx.core.modelwrapper import ModelWrapper \n",
    "from qonnx.custom_op.registry import getCustomOp\n",
    "import os\n",
    "\n",
    "# 1. åŠ è½½ Step 4 ç”Ÿæˆçš„å­æ¨¡å‹\n",
    "# ç¡®ä¿ build_dir å˜é‡å­˜åœ¨ (å¦‚æœåœ¨æ–°å¼€çš„ notebook é‡Œï¼Œè®°å¾—é‡æ–°å®šä¹‰ä¸€ä¸‹ build_dir)\n",
    "if 'build_dir' not in locals():\n",
    "    build_dir = os.environ[\"FINN_BUILD_DIR\"] + \"/lenet_build\"\n",
    "\n",
    "model_path = build_dir + \"/lenet_dataflow_model.onnx\"\n",
    "model = ModelWrapper(model_path)\n",
    "\n",
    "print(\"ğŸš€ å¼€å§‹ Step 5: é…ç½®å¹¶è¡Œåº¦ (Folding)...\")\n",
    "\n",
    "# ==============================================================================\n",
    "# A. é…ç½® MVAU (çŸ©é˜µå‘é‡è®¡ç®—å•å…ƒ)\n",
    "# ==============================================================================\n",
    "# è·å–æ‰€æœ‰ HLS ç‰ˆæœ¬çš„ MVAU\n",
    "# mvau_layers = model.get_nodes_by_op_type(\"MVAU_hls\")\n",
    "\n",
    "# for node in mvau_layers:\n",
    "#     inst = getCustomOp(node)\n",
    "    \n",
    "#     # è·å–å½¢çŠ¶: MW=è¾“å…¥å®½, MH=è¾“å‡ºå®½\n",
    "#     mw = inst.get_nodeattr(\"MW\") \n",
    "#     mh = inst.get_nodeattr(\"MH\")\n",
    "    \n",
    "#     # --- è‡ªåŠ¨è®¡ç®—ç­–ç•¥ ---\n",
    "#     # è§„åˆ™ï¼šPE å¿…é¡»æ•´é™¤ MHï¼ŒSIMD å¿…é¡»æ•´é™¤ MW\n",
    "    \n",
    "#     # 1. è®¾ç½® PE (è¾“å‡ºå¹¶è¡Œåº¦)\n",
    "#     if mh % 8 == 0: pe = 8\n",
    "#     elif mh % 4 == 0: pe = 4\n",
    "#     elif mh % 2 == 0: pe = 2\n",
    "#     else: pe = 1\n",
    "        \n",
    "#     # 2. è®¾ç½® SIMD (è¾“å…¥å¹¶è¡Œåº¦)\n",
    "#     if mw % 8 == 0: simd = 8\n",
    "#     elif mw % 4 == 0: simd = 4\n",
    "#     elif mw % 2 == 0: simd = 2\n",
    "#     else: simd = 1\n",
    "        \n",
    "#     inst.set_nodeattr(\"PE\", pe)\n",
    "#     inst.set_nodeattr(\"SIMD\", simd)\n",
    "    \n",
    "#     # è®¾ç½® FIFO\n",
    "#     inst.set_nodeattr(\"inFIFODepths\", [32])\n",
    "#     inst.set_nodeattr(\"outFIFODepths\", [32])\n",
    "    \n",
    "#     print(f\"Layer {node.name}: Shape({mw},{mh}) -> PE={pe}, SIMD={simd}\")\n",
    "\n",
    "from qonnx.custom_op.registry import getCustomOp\n",
    "\n",
    "fc_layers = model.get_nodes_by_op_type(\"MVAU_hls\")\n",
    "\n",
    "# æ ¼å¼: (PE, SIMD, FIFO_depth)\n",
    "# æ³¨æ„ï¼šæˆ‘åœ¨ FC1 å’Œ Conv2 åšäº†å¦¥åï¼Œé™ä½äº† SIMD ä»¥ç¡®ä¿æ¿å¡èƒ½è·‘é€š\n",
    "folding = [\n",
    "    (8, 5, [32]),\n",
    "    (16, 10, [32]), \n",
    "    (8, 8, [32]), \n",
    "    (1, 1, [32]), \n",
    "    (1, 1, [32]), \n",
    "]\n",
    "\n",
    "for fcl, (pe, simd, fifo_depth) in zip(fc_layers, folding):\n",
    "    fcl_inst = getCustomOp(fcl)\n",
    "    \n",
    "    # 1. è®¾ç½®å¹¶è¡Œåº¦\n",
    "    fcl_inst.set_nodeattr(\"PE\", pe)\n",
    "    fcl_inst.set_nodeattr(\"SIMD\", simd)\n",
    "    fcl_inst.set_nodeattr(\"inFIFODepths\", fifo_depth)\n",
    "    fcl_inst.set_nodeattr(\"outFIFODepths\", fifo_depth) \n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# B. é…ç½® SWG (å·ç§¯è¾“å…¥ç”Ÿæˆå™¨)\n",
    "# ==============================================================================\n",
    "# å°è¯•æŸ¥æ‰¾ RTL æˆ– HLS ç‰ˆæœ¬çš„èŠ‚ç‚¹\n",
    "swg_layers = model.get_nodes_by_op_type(\"ConvolutionInputGenerator_rtl\") \n",
    "if len(swg_layers) == 0:\n",
    "    swg_layers = model.get_nodes_by_op_type(\"ConvolutionInputGenerator_hls\")\n",
    "\n",
    "for node in swg_layers:\n",
    "    inst = getCustomOp(node)\n",
    "    \n",
    "    # å®‰å…¨èµ·è§è®¾ä¸º 1ï¼Œç¡®ä¿é€šè¿‡ç»¼åˆ\n",
    "    inst.set_nodeattr(\"SIMD\", 1) \n",
    "    inst.set_nodeattr(\"inFIFODepths\", [32])\n",
    "    inst.set_nodeattr(\"outFIFODepths\", [32])\n",
    "    print(f\"Layer {node.name}: SIMD=1 (Safe Mode)\")\n",
    "\n",
    "# ==============================================================================\n",
    "# C. é…ç½® Thresholding (é˜ˆå€¼å±‚)\n",
    "# ==============================================================================\n",
    "thresh_layers = model.get_nodes_by_op_type(\"Thresholding_rtl\")\n",
    "if len(thresh_layers) == 0:\n",
    "     thresh_layers = model.get_nodes_by_op_type(\"Thresholding_hls\")\n",
    "\n",
    "for node in thresh_layers:\n",
    "    inst = getCustomOp(node)\n",
    "    inst.set_nodeattr(\"PE\", 1) \n",
    "    inst.set_nodeattr(\"outFIFODepths\", [32])\n",
    "\n",
    "# ==============================================================================\n",
    "# ä¿å­˜ç»“æœ\n",
    "# ==============================================================================\n",
    "model.save(build_dir + \"/lenet_folded.onnx\")\n",
    "print(f\"âœ… Step 5 å®Œæˆï¼æ¨¡å‹å·²ä¿å­˜è‡³: {build_dir}/lenet_folded.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5c387939-5d67-428a-9d64-426109464e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serving 'output_lenet/lenet_folded.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7d8587068730>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(build_dir + \"/lenet_folded.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ce0a8e2-5db7-48fb-a196-bdd8b041390b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxwellqin/projects/finn/src/finn/transformation/fpgadataflow/floorplan.py:107: UserWarning: 20 nodes have no entry in the provided floorplan, SLR was set to -1\n",
      "  warnings.warn(\n",
      "/home/maxwellqin/projects/finn/src/finn/transformation/fpgadataflow/insert_fifo.py:234: UserWarning: Input FIFO for IODMA_hls_0_out0 has depth 2 and won't\n",
      "                        be created. This may cause RTL simulation issues.\n",
      "                        \n",
      "  warnings.warn(\n",
      "/home/maxwellqin/projects/finn/src/finn/transformation/fpgadataflow/insert_fifo.py:294: UserWarning: Output FIFO for LabelSelect_hls_0_out0 has depth 2 and won't\n",
      "                        be created. This may cause RTL simulation issues.\n",
      "                        \n",
      "  warnings.warn(\n",
      "/home/maxwellqin/projects/finn/src/finn/transformation/fpgadataflow/create_stitched_ip.py:290: UserWarning: First node is not StreamingFIFO or IODMA.\n",
      "                You may experience incorrect stitched-IP rtlsim or hardware\n",
      "                behavior. It is strongly recommended to insert FIFOs prior to\n",
      "                calling CreateStitchedIP.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from finn.transformation.fpgadataflow.make_zynq_proj import ZynqBuild\n",
    "model = ModelWrapper(build_dir + \"/lenet_folded.onnx\")\n",
    "model = model.transform(ZynqBuild(platform = pynq_board, period_ns = target_clk_ns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "262e6b57-566f-4fbd-a4b8-5a5a2cbfef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.make_pynq_driver import MakePYNQDriver\n",
    "model = model.transform(MakePYNQDriver(\"zynq-iodma\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae8d9aeb-63f4-4254-b1cd-82435bc85832",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(build_dir + \"/lenet_synth.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "414cf3fc-666c-4e9f-ab0d-2708dedfa402",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "creating /home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv/runtime_weights\n",
      "creating /home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv/finn\n",
      "creating /home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv/finn/util\n",
      "copying /home/maxwellqin/projects/finn/build_output/pynq_driver_qxy7whml/finn/util/data_packing.py -> /home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv/finn/util\n",
      "copying /home/maxwellqin/projects/finn/build_output/pynq_driver_qxy7whml/finn/util/__init__.py -> /home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv/finn/util\n",
      "copying /home/maxwellqin/projects/finn/build_output/pynq_driver_qxy7whml/validate.py -> /home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv\n",
      "copying /home/maxwellqin/projects/finn/build_output/pynq_driver_qxy7whml/driver.py -> /home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv\n",
      "copying /home/maxwellqin/projects/finn/build_output/pynq_driver_qxy7whml/driver_base.py -> /home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv\n",
      "creating /home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv/qonnx\n",
      "creating /home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv/qonnx/util\n",
      "copying /home/maxwellqin/projects/finn/build_output/pynq_driver_qxy7whml/qonnx/util/__init__.py -> /home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv/qonnx/util\n",
      "copying /home/maxwellqin/projects/finn/build_output/pynq_driver_qxy7whml/qonnx/util/basic.py -> /home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv/qonnx/util\n",
      "creating /home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv/qonnx/core\n",
      "copying /home/maxwellqin/projects/finn/build_output/pynq_driver_qxy7whml/qonnx/core/datatype.py -> /home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv/qonnx/core\n",
      "copying /home/maxwellqin/projects/finn/build_output/pynq_driver_qxy7whml/qonnx/core/__init__.py -> /home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv/qonnx/core\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv/finn/util/data_packing.py',\n",
       " '/home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv/finn/util/__init__.py',\n",
       " '/home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv/validate.py',\n",
       " '/home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv/driver.py',\n",
       " '/home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv/driver_base.py',\n",
       " '/home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv/qonnx/util/__init__.py',\n",
       " '/home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv/qonnx/util/basic.py',\n",
       " '/home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv/qonnx/core/datatype.py',\n",
       " '/home/maxwellqin/projects/finn/build_output/pynq_deployment_kedrbovv/qonnx/core/__init__.py']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shutil import copy\n",
    "from distutils.dir_util import copy_tree\n",
    "from finn.util.basic import make_build_dir\n",
    "\n",
    "# create directory for deployment files\n",
    "deployment_dir = make_build_dir(prefix=\"pynq_deployment_\")\n",
    "model.set_metadata_prop(\"pynq_deployment_dir\", deployment_dir)\n",
    "\n",
    "# get and copy necessary files\n",
    "# .bit and .hwh file\n",
    "bitfile = model.get_metadata_prop(\"bitfile\")\n",
    "hwh_file = model.get_metadata_prop(\"hw_handoff\")\n",
    "deploy_files = [bitfile, hwh_file]\n",
    "\n",
    "for dfile in deploy_files:\n",
    "    if dfile is not None:\n",
    "        copy(dfile, deployment_dir)\n",
    "\n",
    "# driver.py and python libraries\n",
    "pynq_driver_dir = model.get_metadata_prop(\"pynq_driver_dir\")\n",
    "copy_tree(pynq_driver_dir, deployment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5247acb-d3f5-4796-98b8-d98c52e3fc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
