import os
import sys

# 1. è§£å†³ OMP å†²çª (å¿…é¡»åœ¨æœ€å‰é¢)
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from torchvision import datasets, transforms
import brevitas.nn as qnn
import numpy as np
from brevitas.inject.enum import ScalingImplType
from brevitas.export import export_qonnx
from brevitas.core.zero_point import ZeroZeroPoint 

# [å…³é”®ä¿®å¤] å¼•å…¥æ‰€æœ‰åº•å±‚ä¾èµ–ï¼Œä¸å†ä¾èµ–è‡ªåŠ¨æ¨æ–­
from brevitas.inject import ExtendedInjector
from brevitas.core.quant import BinaryQuant  # æ ¸å¿ƒé‡åŒ–ç®—æ³•
from brevitas.core.scaling import ConstScaling # ç¼©æ”¾å®ç°
from brevitas.core.restrict_val import RestrictValueType # çº¦æŸç±»å‹
from brevitas.proxy.runtime_quant import ActQuantProxyFromInjector # ä»£ç†ç±»
from types import ModuleType

# --- å¼•å…¥ ONNX æ¨ç†åº“ ---
try:
    import onnxruntime as ort
    ONNX_RUNTIME_AVAILABLE = True
except ImportError:
    print("âš ï¸ è­¦å‘Š: æœªå®‰è£… onnxruntime. æ— æ³•è¿›è¡Œ ONNX æ¨¡å‹æ¨ç†éªŒè¯.")
    ONNX_RUNTIME_AVAILABLE = False

# --- å¼•å…¥ matplotlib ç”¨äºç»˜å›¾ ---
try:
    import matplotlib.pyplot as plt
    plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial Unicode MS', 'sans-serif']
    plt.rcParams['axes.unicode_minus'] = False  
    MATPLOTLIB_AVAILABLE = True
except ImportError:
    print("âš ï¸ è­¦å‘Š: æœªå®‰è£… matplotlib. æ— æ³•ç»˜åˆ¶è®­ç»ƒæ›²çº¿.")
    MATPLOTLIB_AVAILABLE = False
# -------------------------

# 2. è§£å†³ ONNXOptimizer ç¼ºå¤± (FINNç¯å¢ƒå…¼å®¹æ€§ä¿®å¤)
fake_opt = ModuleType("onnxoptimizer")
fake_opt.optimize = lambda model, passes=None, fixed_point=False: model
sys.modules["onnxoptimizer"] = fake_opt

# 3. ç¡®å®šè®¾å¤‡
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {device} | å¯åŠ¨ W2A1 å¯¹ç§°é‡åŒ–è®­ç»ƒ...")

# ==============================================================================
# [ç»ˆæä¿®å¤] æ‰‹åŠ¨å…¨é…ç½® Bipolar é‡åŒ–å™¨
# æ˜¾å¼å®šä¹‰æ‰€æœ‰å±æ€§ï¼Œé˜²æ­¢ NoneType é”™è¯¯
# ==============================================================================
class CommonBinaryActQuant(ExtendedInjector):
    # 1. ç»“æ„ä¾èµ–
    proxy_class = ActQuantProxyFromInjector
    tensor_quant = BinaryQuant
    scaling_impl = ConstScaling
    
    # 2. å‚æ•°é…ç½®
    bit_width = 1
    min_val = -1.0
    max_val = 1.0
    scaling_init = 1.0
    restrict_scaling_type = RestrictValueType.FP
    
    # [å…³é”®ä¿®å¤] æ˜¾å¼å£°æ˜ç¬¦å·å±æ€§ï¼Œè§£å†³ TypeError: 'NoneType'
    signed = True
    is_signed = True
    
    # å…¶ä»–
    return_quant_tensor = False
    zero_point_impl = ZeroZeroPoint

# ==============================================================================
# 2. ç½‘ç»œå®šä¹‰ï¼šæ ¸å¿ƒ W2A1 (æƒé‡2bit, æ¿€æ´»1bit Bipolar)
# ==============================================================================
class LeNet_W2A1_MixedPrecision(nn.Module):
    def __init__(self):
        super(LeNet_W2A1_MixedPrecision, self).__init__()
        
        # =======================================================
        # 1. æ¿€æ´»é…ç½® (Act)
        # =======================================================
        kwargs_act_input = {
            'quant_type': 'INT', 'bit_width': 2, 
            'min_val': 0.0, 'max_val': 1.0, 
            'scaling_impl_type': ScalingImplType.CONST, 'scaling_const': 1.0,
            'return_quant_tensor': False, 'zero_point_impl': ZeroZeroPoint 
        }
        
        # æ ¸å¿ƒæ¿€æ´»
        kwargs_act_core = {
            'act_quant': CommonBinaryActQuant,
            'return_quant_tensor': False 
        }

        # =======================================================
        # 2. æƒé‡é…ç½® (Weight)
        # =======================================================
        base_weight_kwargs = {
            'quant_type': 'INT', 
            'scaling_impl_type': ScalingImplType.CONST, 
            'scaling_const': 1.0,
            'return_quant_tensor': False, 
            'bias': False, 
            'narrow_range': True, 
            'zero_point_impl': ZeroZeroPoint
        }

        kwargs_weight_core = base_weight_kwargs.copy()
        kwargs_weight_core['weight_bit_width'] = 2 

        kwargs_weight_begin = base_weight_kwargs.copy()
        kwargs_weight_begin['weight_bit_width'] = 2

        kwargs_weight_end = base_weight_kwargs.copy()
        kwargs_weight_end['weight_bit_width'] = 2

        # =======================================================
        # 3. ç½‘ç»œå±‚å®šä¹‰
        # =======================================================
        self.quant_input = qnn.QuantIdentity(**kwargs_act_input)

        # Layer 1: Conv1
        self.conv1 = qnn.QuantConv2d(1, 8, kernel_size=5, padding=0, **kwargs_weight_begin)
        self.bn1 = nn.BatchNorm2d(8, eps=1e-3)
        self.act1 = qnn.QuantIdentity(**kwargs_act_core) 
        self.pool1 = nn.MaxPool2d(2, 2)

        # Layer 2: Conv2
        self.conv2 = qnn.QuantConv2d(8, 16, kernel_size=5, padding=0, **kwargs_weight_core)
        self.bn2 = nn.BatchNorm2d(16, eps=1e-3)
        self.act2 = qnn.QuantIdentity(**kwargs_act_core)
        self.pool2 = nn.MaxPool2d(2, 2)

        # Layer 3: Conv3
        self.conv3 = qnn.QuantConv2d(16, 32, kernel_size=5, padding=0, **kwargs_weight_core)
        self.bn3 = nn.BatchNorm2d(32, eps=1e-3)
        self.act3 = qnn.QuantIdentity(**kwargs_act_core)

        # FC 1: FC1
        self.fc1 = qnn.QuantLinear(32, 16, **kwargs_weight_core)
        self.act4 = qnn.QuantIdentity(**kwargs_act_core)

        # FC 2: FC2 è¾“å‡ºå±‚
        self.fc2 = qnn.QuantLinear(16, 10, output_quant=None, **kwargs_weight_end)

        self._init_weights()

    def _init_weights(self):
        print("ğŸ”§ åˆå§‹åŒ–æƒé‡ (Uniform -0.8 ~ 0.8)...")
        for m in self.modules():
            if isinstance(m, (qnn.QuantConv2d, qnn.QuantLinear)):
                nn.init.uniform_(m.weight, -0.8, 0.8)

    def forward(self, x):
        x = self.quant_input(x)
        x = self.pool1(self.act1(self.bn1(self.conv1(x))))
        x = self.pool2(self.act2(self.bn2(self.conv2(x))))
        x = self.act3(self.bn3(self.conv3(x)))
        x = x.view(x.shape[0], -1)
        x = self.act4(self.fc1(x))
        x = self.fc2(x)
        return x

# ==============================================================================
# 3. è¯„ä¼°å‡½æ•°
# ==============================================================================
def evaluate_model(model, data_loader, criterion, mode="éªŒè¯"):
    model.eval()
    total_loss = 0
    correct = 0
    dataset_size = len(data_loader.dataset)
    
    with torch.no_grad():
        for data, target in data_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            total_loss += criterion(output, target).item() 
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()

    avg_loss = total_loss / dataset_size
    accuracy = 100. * correct / dataset_size

    print(f"\nğŸ”¬ PyTorch {mode}é›†ç»“æœ: å¹³å‡æŸå¤±={avg_loss:.4f}, å‡†ç¡®ç‡={correct}/{dataset_size} ({accuracy:.2f}%)")
    return avg_loss, accuracy

# ==============================================================================
# 4. ONNX æ¨ç†æµ‹è¯•å‡½æ•°
# ==============================================================================
def test_onnx_model(onnx_path, test_loader):
    if not ONNX_RUNTIME_AVAILABLE:
        print("âŒ æ— æ³•è¿›è¡Œ ONNX æ¨ç†éªŒè¯ï¼Œè¯·å®‰è£… onnxruntimeã€‚")
        return
    print(f"\nğŸ” å¯åŠ¨ ONNX æ¨¡å‹ ({onnx_path}) ç²¾åº¦éªŒè¯...")

    ort_session = ort.InferenceSession(onnx_path)
    input_name = ort_session.get_inputs()[0].name
    output_name = ort_session.get_outputs()[0].name
    
    correct = 0
    total = 0
    for data, target in test_loader:
        data_np = data.cpu().numpy().astype(np.float32)
        ort_inputs = {input_name: data_np}
        ort_outputs = ort_session.run([output_name], ort_inputs)
        output = torch.from_numpy(np.array(ort_outputs[0]))
        pred = output.argmax(dim=1, keepdim=True)
        correct += pred.eq(target.view_as(pred)).sum().item()
        total += len(data)

    accuracy = 100. * correct / total
    print(f"âœ… ONNX Runtime æµ‹è¯•ç»“æœ: å‡†ç¡®ç‡={correct}/{total} ({accuracy:.2f}%)")

# ==============================================================================
# 5. ä¸»è®­ç»ƒæµç¨‹
# ==============================================================================
def train_symmetric_final():

    transform = transforms.Compose([
        transforms.Resize((32, 32)),
        transforms.ToTensor(), 
        transforms.Normalize((0.1307,), (0.3081,))
    ])
    
    train_val_dataset_full = datasets.MNIST('./data', train=True, download=True, transform=transform)
    test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)
    
    val_split_ratio = 0.1
    val_size = int(val_split_ratio * len(train_val_dataset_full))
    train_size = len(train_val_dataset_full) - val_size
    
    print(f"ğŸ”„ åˆ’åˆ†æ•°æ®é›†: è®­ç»ƒé›† {train_size} å¼ , éªŒè¯é›† {val_size} å¼ .")
    train_dataset, val_dataset = random_split(train_val_dataset_full, [train_size, val_size])
    
    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=1000, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)
    
    model = LeNet_W2A1_MixedPrecision().to(device)
    optimizer = optim.Adam(model.parameters(), lr=0.0005) 
    criterion = nn.CrossEntropyLoss(reduction='sum')
    
    num_epochs = 5
    best_val_acc = 0.0
    train_losses = []
    train_accuracies = []
    val_losses = []
    val_accuracies = []

    for epoch in range(num_epochs):
        model.train()
        print(f"\n=================== Epoch {epoch+1}/{num_epochs} Start ===================")

        epoch_train_loss = 0.0
        epoch_train_correct = 0
        epoch_train_total = 0

        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(device), target.to(device)
            batch_size = data.size(0)

            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()

            epoch_train_loss += loss.item()
            pred = output.argmax(dim=1, keepdim=True)
            epoch_train_correct += pred.eq(target.view_as(pred)).sum().item()
            epoch_train_total += batch_size

            if batch_idx % 100 == 0:
                print(f"[Step {batch_idx}] Loss={loss.item()/batch_size:.4f}")

        avg_train_loss = epoch_train_loss / epoch_train_total
        train_accuracy = 100. * epoch_train_correct / epoch_train_total
        train_losses.append(avg_train_loss)
        train_accuracies.append(train_accuracy)

        val_loss, val_acc = evaluate_model(model, val_loader, criterion, mode="éªŒè¯")
        val_losses.append(val_loss)
        val_accuracies.append(val_acc)

        if val_acc > best_val_acc:
            best_val_acc = val_acc
            print(f"ğŸ† æ–°çš„æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%ï¼Œæ¨¡å‹å·²æ›´æ–°ã€‚")

        print(f"=================== Epoch {epoch+1} Complete (Val Acc: {val_acc:.2f}%) ===================")

    print(f"\n{'#'*60}")
    print("ğŸ¯ è®­ç»ƒå®Œæˆï¼å¼€å§‹æœ€ç»ˆæµ‹è¯• (ä½¿ç”¨ç‹¬ç«‹çš„æµ‹è¯•é›†)...")
    test_loss, test_acc = evaluate_model(model, test_loader, criterion, mode="æœ€ç»ˆæµ‹è¯•")
    print(f"################### æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡ (PyTorch): {test_acc:.2f}% ###################")

    if MATPLOTLIB_AVAILABLE:
        print("\nğŸ“Š ç»˜åˆ¶è®­ç»ƒè¿‡ç¨‹æ›²çº¿...")
        epochs = range(1, num_epochs + 1)
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
        ax1.plot(epochs, train_losses, 'b-', label='Training Loss')
        ax1.plot(epochs, val_losses, 'r-', label='Validation Loss')
        ax1.set_title('Loss')
        ax1.legend()
        ax2.plot(epochs, train_accuracies, 'b-', label='Training Accuracy')
        ax2.plot(epochs, val_accuracies, 'r-', label='Validation Accuracy')
        ax2.set_title('Accuracy')
        ax2.legend()
        plt.tight_layout()
        plt.savefig('training_curves.png')
        plt.show()

    output_path = "lenet_w2a1_mixed.onnx"
    print(f"\nğŸ“¤ å¯¼å‡ºONNXæ¨¡å‹: {output_path}")
    model.eval()
    model_cpu = model.to('cpu')
    dummy_input = torch.rand(1, 1, 32, 32).to('cpu') 
    
    try:
        export_qonnx(model_cpu, dummy_input, output_path, opset_version=11)
        print(f"ğŸ‰ æˆåŠŸå¯¼å‡º: {output_path}")
        print("ğŸ’¡ æç¤º: æ¨¡å‹ç°å·²åŒ…å« Bipolar å±æ€§ (bias=-1, scale=2)ã€‚")
    except Exception as e:
        print(f"âŒ å¯¼å‡ºONNXå¤±è´¥: {e}")

    if ONNX_RUNTIME_AVAILABLE:
        test_onnx_model(output_path, test_loader)
    
if __name__ == '__main__':
    train_symmetric_final()